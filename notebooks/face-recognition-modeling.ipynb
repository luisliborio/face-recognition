{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8450847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Adiciona a pasta principal ao sys.path para podermos importar modulos de myutils\n",
    "main_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if main_path not in sys.path:\n",
    "    sys.path.append(main_path)\n",
    "\n",
    "# silenciar avisos do TF\n",
    "\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_VLOG_LEVEL'] = '0'\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import imtools\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n",
    "# import data_wrangling as dw\n",
    "import importlib\n",
    "from absl import logging\n",
    "\n",
    "# Define o nível de logging para silenciar os avisos do TF\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "device = tf.config.list_physical_devices('GPU')[0]\n",
    "tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfad9ab6",
   "metadata": {},
   "source": [
    "# CelebA dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bd8d21",
   "metadata": {},
   "source": [
    "a partir dos metadados de identidade, extraimos um dataframe com [path, id], onde cada id pertende a uma pessoa única"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4ded10",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_dir = \"../data/celebA/identity_CelebA.txt\"\n",
    "\n",
    "df = pd.read_csv(anno_dir, sep=' ', header=None, names=['path', 'id']).sort_values('id').reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd22a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizando todas as fotos de um id aleatório\n",
    "id = np.random.choice(np.arange(1, 10178), 1)[0]\n",
    "random_person = df[df['id'] == id]\n",
    "imgs = []\n",
    "for i, row in random_person.iterrows():\n",
    "    path = os.path.join(\"../data/celebA/images/\", row['path'])\n",
    "    imgs.append(imtools.load_image(path))\n",
    "\n",
    "print(id)\n",
    "imtools.plot_grid(imgs, scale=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e7ef7c",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf6e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "unique_ids = df['id'].unique()\n",
    "train_ids, test_ids = train_test_split(unique_ids, test_size=0.001, random_state=42)\n",
    "\n",
    "train_df = df[df['id'].isin(train_ids)].reset_index(drop=True)\n",
    "test_df = df[df['id'].isin(test_ids)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081cc4b0",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989f032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose([    \n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Affine(scale=(0.75, 1.2), translate_percent=(-0.1, 0.1), rotate=(-15, 15), shear=(-10, 10), border_mode=1, p=0.8),\n",
    "    A.RandomOrder([        \n",
    "        A.CLAHE(),\n",
    "        A.RandomBrightnessContrast(),\n",
    "        A.GaussianBlur(3),\n",
    "        A.GaussNoise(std_range=(0.005, 0.05)),\n",
    "        A.OneOf([\n",
    "            A.ToGray(),\n",
    "            A.ToSepia(),            \n",
    "        ]),\n",
    "        A.OneOf([\n",
    "            A.RGBShift((-20, 20), (-20, 20), (-20, 20)),\n",
    "            A.ColorJitter(brightness=(0.95, 1.05), contrast=(0.95, 1.05), saturation=(0.95, 1.05), hue=(-0.05, 0.05))\n",
    "        ]),\n",
    "        A.GridDistortion(\n",
    "            num_steps=3,\n",
    "            distort_limit=[-0.1, 0.1],\n",
    "            interpolation=cv2.INTER_LINEAR,\n",
    "            normalized=True,\n",
    "            mask_interpolation=cv2.INTER_NEAREST,\n",
    "        ),\n",
    "        A.OpticalDistortion(distort_limit=(-0.2, 0.2)),\n",
    "        A.Perspective(scale=(0.01, 0.08)),\n",
    "        A.Posterize(num_bits=(4, 7)),\n",
    "        A.Defocus(radius=(1, 3)) \n",
    "    ], n=4),\n",
    "    \n",
    "])\n",
    "\n",
    "transform_test = A.Compose([\n",
    "    A.RandomOrder([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Affine(scale=(0.85, 1.1), translate_percent=(-0.1, 0.1), rotate=(-15, 15), shear=(-5, 5), border_mode=1, p=0.8),\n",
    "        A.RGBShift((-10, 10), (-10, 10), (-10, 10)),\n",
    "        A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.75),\n",
    "        A.OpticalDistortion(distort_limit=(-0.1, 0.1), p=0.75),\n",
    "        A.Perspective(scale=(0.01, 0.05), p=0.75),        \n",
    "    ], n=4)\n",
    "])\n",
    "\n",
    "augment_train = lambda img: transform_train(image=img)['image']\n",
    "augment_test = lambda img: transform_test(image=img)['image']\n",
    "\n",
    "\n",
    "######################\n",
    "# Avaliando a qualidade da transformada\n",
    "id = np.random.choice(np.arange(1, 10178), 1)[0]\n",
    "random_person = df[df['id'] == id]\n",
    "imgs = []\n",
    "imgs_auged = []\n",
    "for i, row in random_person.iterrows():\n",
    "    path = os.path.join(\"../data/celebA/images/\", row['path'])    \n",
    "    img = imtools.load_image(path)\n",
    "    imgs.append(img)\n",
    "    imgs_auged.append(augment_test(img))\n",
    "\n",
    "print(id)\n",
    "n = len(imgs)\n",
    "if n > 5:\n",
    "    n = 5\n",
    "imtools.plot_images(imgs[:n-1], scale=3)\n",
    "imtools.plot_images(imgs_auged[:n-1], scale=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbd1090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# triplet dataset\n",
    "def get_dataset(anno_df, batch_size, kshots=1, img_size=224, transform=None, drop=False, shuffle=False):    \n",
    "    def gen():        \n",
    "        while True:\n",
    "            positive_idx, negative_idx = np.random.choice(anno_df['id'], 2, replace=False)\n",
    "            \n",
    "            # path | id df\n",
    "            positive_obs = anno_df[anno_df['id'] == positive_idx]\n",
    "            negative_obs = anno_df[anno_df['id'] == negative_idx]\n",
    "\n",
    "            # sortear K-shot dos suportes triplet\n",
    "            positive_obs = positive_obs.sample(kshots+1, replace=True) # query é a amostra +1\n",
    "            negative_obs = negative_obs.sample(kshots, replace=True)\n",
    "\n",
    "            # separar query de positives\n",
    "            query_obs = positive_obs.iloc[-1]\n",
    "            positive_obs = positive_obs.iloc[:-1]\n",
    "                        \n",
    "            # carregar e guardar imagens em listas\n",
    "            positive_imgs = []\n",
    "            negative_imgs = []\n",
    "            query_imgs = []\n",
    "            for i, row in positive_obs.iterrows():\n",
    "                path = os.path.join(\"../data/celebA/images/\", row['path'])\n",
    "                positive_imgs.append(imtools.load_image(path, size=(img_size, img_size)))\n",
    "            for i, row in negative_obs.iterrows():\n",
    "                path = os.path.join(\"../data/celebA/images/\", row['path'])\n",
    "                negative_imgs.append(imtools.load_image(path, size=(img_size, img_size)))\n",
    "\n",
    "            # só há um query que será multiplicado com augmentation por Kshots\n",
    "            path = os.path.join(\"../data/celebA/images/\", query_obs['path'])\n",
    "            query_img = imtools.load_image(path, size=(img_size, img_size))\n",
    "\n",
    "            # augmentation\n",
    "            if transform is not None:\n",
    "                positive_imgs = [transform(img) for img in positive_imgs]\n",
    "                negative_imgs = [transform(img) for img in negative_imgs]\n",
    "                query_imgs = [transform(query_img) for _ in range(kshots)] # multiplicando query com augmentation\n",
    "            else: # repetir o query para preservar compatibilidade do output_signature\n",
    "                query_imgs = [query_img for _ in range(kshots)]\n",
    "\n",
    "            # to tensor\n",
    "            p_inputs = np.array(positive_imgs).astype('float32')\n",
    "            n_inputs = np.array(negative_imgs).astype('float32')\n",
    "            q_inputs = np.array(query_imgs).astype('float32')\n",
    "            \n",
    "            yield p_inputs, n_inputs, q_inputs\n",
    "    \n",
    "    output_signature = (\n",
    "        tf.TensorSpec(shape=(kshots, img_size, img_size, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(kshots, img_size, img_size, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(kshots, img_size, img_size, 3), dtype=tf.float32)\n",
    "    )\n",
    "\n",
    "    ds = tf.data.Dataset.from_generator(gen, output_signature=output_signature)\n",
    "    ds = ds.shuffle(batch_size*8) if shuffle else ds\n",
    "    ds = ds.batch(batch_size, drop_remainder=drop)\n",
    "    ds = ds.prefetch(20)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22265d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "KSHOTS = 5\n",
    "train_ds = get_dataset(anno_df=train_df,\n",
    "                       batch_size=BATCH_SIZE,\n",
    "                       kshots=KSHOTS,\n",
    "                       img_size=224,\n",
    "                       transform=augment_train,\n",
    "                       drop=True,\n",
    "                       shuffle=False)\n",
    "\n",
    "test_ds = get_dataset(anno_df=test_df,\n",
    "                       batch_size=BATCH_SIZE,\n",
    "                       kshots=KSHOTS,\n",
    "                       img_size=224,\n",
    "                       transform=augment_test,\n",
    "                       drop=True,\n",
    "                       shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13828471",
   "metadata": {},
   "outputs": [],
   "source": [
    "for P, N, Q in test_ds:\n",
    "    break\n",
    "\n",
    "print(P.shape, N.shape, Q.shape)\n",
    "\n",
    "imtools.plot_images(P[0,].numpy().astype('uint8'), scale=3)\n",
    "imtools.plot_images(N[0,].numpy().astype('uint8'), scale=3)\n",
    "imtools.plot_images(Q[0,].numpy().astype('uint8'), scale=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050c627c",
   "metadata": {},
   "source": [
    "## FaceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e78b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@K.utils.register_keras_serializable(package='Custom')\n",
    "def l2norm(x):\n",
    "    return tf.nn.l2_normalize(x, axis=1)\n",
    "\n",
    "\n",
    "@K.utils.register_keras_serializable(package='Custom')\n",
    "def build_feature_extractor(input_shape, backbone, dim=512):\n",
    "    def self_attention(layer,):\n",
    "        x = K.layers.Dropout(0.5)(layer)\n",
    "        x = K.layers.Dense(dim // 2, activation='gelu')(x)\n",
    "        att_mask = K.layers.Dense(dim, activation='sigmoid')(x)\n",
    "\n",
    "        x = K.layers.Dropout(0.5)(layer)\n",
    "        x = K.layers.Dense(dim)(x)\n",
    "\n",
    "        return x * att_mask\n",
    "    \n",
    "    backbone.trainable = False\n",
    "    \n",
    "    inputs = K.layers.Input(shape=input_shape)\n",
    "\n",
    "    # feature extraction\n",
    "    embeddings = backbone(inputs, training=False)\n",
    "    \n",
    "    # vectorize\n",
    "    x = K.layers.GlobalAveragePooling2D()(embeddings)\n",
    "    x = self_attention(x)\n",
    "    outputs = K.layers.Lambda(l2norm)(x)\n",
    "\n",
    "    feature_extractor = K.Model(inputs, outputs)\n",
    "    return feature_extractor\n",
    "\n",
    "\n",
    "@K.utils.register_keras_serializable(package='Custom')\n",
    "class FaceModel(K.Model):\n",
    "    def __init__(self, feature_extractor, dim=512, margin=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.feature_extractor=feature_extractor\n",
    "        self.margin=margin\n",
    "        self.dim=dim\n",
    "        self.triplet_loss_tracker=K.metrics.Mean(name='loss')\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.triplet_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def compute_loss(self, p, n, q):\n",
    "        \"soft margin semi-hard negatives\"\n",
    "\n",
    "        p_dist = tf.reduce_sum(tf.square(p - q), axis=1) # (batch, dim) -> (batch,)\n",
    "        n_dist = tf.reduce_sum(tf.square(n - q), axis=1)\n",
    "\n",
    "        # dp < dn < dp + margin\n",
    "        # mask = tf.logical_and(p_dist < n_dist, n_dist < (p_dist + self.margin)) # (batch, 1) bool\n",
    "\n",
    "        diff = p_dist - n_dist # (batch,)\n",
    "        soft_loss = tf.math.log1p(tf.exp(diff)) # (batch,)\n",
    "        loss = soft_loss\n",
    "\n",
    "        # manter apenas as distâncias moderadas\n",
    "        # loss = tf.boolean_mask(soft_loss, mask) # (batch,)\n",
    "        return tf.reduce_mean(loss) # em caso de mask ser all False TODO: VERIFICAR MÉDIA COM MASK \n",
    "\n",
    "    def train_step(self, data):\n",
    "        with K.backend.name_scope('train'):                    \n",
    "            p_episodes, n_episodes, q_episodes = data                                         \n",
    "            num_episodes = p_episodes.shape[0] # equivalente ao batch_size            \n",
    "                        \n",
    "            with tf.GradientTape() as tape:\n",
    "                # (batch, dim) vai armazenar todas as inferências de cada classe \n",
    "                # Criando TensorArrays dinâmicos\n",
    "                p_batch_pred = tf.TensorArray(tf.float32, size=num_episodes)\n",
    "                n_batch_pred = tf.TensorArray(tf.float32, size=num_episodes)\n",
    "                q_batch_pred = tf.TensorArray(tf.float32, size=num_episodes)\n",
    "                for episode in range(num_episodes): # (# batch iterações)\n",
    "                    p_inputs, n_inputs, q_inputs = p_episodes[episode], n_episodes[episode], q_episodes[episode]\n",
    "\n",
    "                    # transforma todas as entradas em um único batch de (3*kshots, H, W, 3)\n",
    "                    inputs = tf.concat([p_inputs, n_inputs, q_inputs], axis=0) # (P + N + Q)\n",
    "                    kshots = inputs.shape[0] // 3\n",
    "\n",
    "                    # extração de todos os vetores\n",
    "                    embeddings = self.feature_extractor(inputs)\n",
    "                    \n",
    "                    # split de cada classe\n",
    "                    p_embeddings = embeddings[0:kshots]\n",
    "                    n_embeddings = embeddings[kshots:2*kshots]\n",
    "                    q_embeddings = embeddings[-kshots:]\n",
    "\n",
    "                    # médias do K-shot\n",
    "                    p_vector = tf.reduce_mean(p_embeddings, axis=0)\n",
    "                    n_vector = tf.reduce_mean(n_embeddings, axis=0)\n",
    "                    q_vector = tf.reduce_mean(q_embeddings, axis=0)\n",
    "\n",
    "                    # preencher os tensores dinâmicos\n",
    "                    p_batch_pred = p_batch_pred.write(episode, p_vector)\n",
    "                    n_batch_pred = n_batch_pred.write(episode, n_vector)\n",
    "                    q_batch_pred = q_batch_pred.write(episode, q_vector)\n",
    "                    \n",
    "                # após todas as inferências, recuperar o valor final (Batch, dim)\n",
    "                p_batch_pred = p_batch_pred.stack()\n",
    "                n_batch_pred = n_batch_pred.stack()\n",
    "                q_batch_pred = q_batch_pred.stack()\n",
    "                \n",
    "                # soft margin semi-hard triplet loss\n",
    "                loss = self.compute_loss(p_batch_pred, n_batch_pred, q_batch_pred)\n",
    "\n",
    "            grads = tape.gradient(loss, self.feature_extractor.trainable_weights)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.feature_extractor.trainable_weights))\n",
    "\n",
    "            # atualizar trackers\n",
    "            self.triplet_loss_tracker.update_state(loss)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "                \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"feature_extractor\": K.utils.serialize_keras_object(self.feature_extractor),\n",
    "            \"margin\": self.margin,\n",
    "            \"dim\": self.dim\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        fe_ser = config.pop(\"feature_extractor\")        \n",
    "        feature_extractor = K.utils.deserialize_keras_object(fe_ser)\n",
    "        \n",
    "        margin = config.pop(\"margin\", 0.2)\n",
    "        dim = config.pop(\"dim\", 512)\n",
    "\n",
    "        return cls(feature_extractor=feature_extractor, margin=margin, dim=dim, **config)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Build model\n",
    "# ----------------------------\n",
    "backbone = K.applications.EfficientNetB0(\n",
    "    include_top=False,    \n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "feature_extractor = build_feature_extractor((224, 224, 3), backbone, dim=512)\n",
    "model = FaceModel(feature_extractor, dim=512, margin=0.2)\n",
    "model.compile(optimizer=K.optimizers.Adam(1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4552b2b0",
   "metadata": {},
   "source": [
    "## callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aabae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p, n, q):\n",
    "    p_dist = tf.reduce_sum(tf.square(p - q), axis=1) # (batch, dim) -> (batch,)\n",
    "    n_dist = tf.reduce_sum(tf.square(n - q), axis=1)\n",
    "\n",
    "    # distâncias negativas para melhor interpretabilidade das métricas\n",
    "    # \"quanto maior -d, mais parecido com o positivo\"\n",
    "    scores = -np.concatenate([p_dist, n_dist])\n",
    "    labels = np.concatenate([np.ones_like(p_dist), np.zeros_like(n_dist)])\n",
    "    \n",
    "    auroc = roc_auc_score(labels, scores)           # ROC-AUC\n",
    "    aupr  = average_precision_score(labels, scores) # PR-AUC\n",
    "\n",
    "    # Youlden's J threshold\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "    J = tpr - fpr\n",
    "    idx = np.argmax(J)\n",
    "    J_threshold = thresholds[idx]\n",
    "\n",
    "    return auroc, aupr, fpr, tpr, J_threshold\n",
    "\n",
    "class VerificationMetrics(K.callbacks.Callback):\n",
    "    def __init__(self, val_ds, compute_fn, steps=10, margin=0.1):\n",
    "        super().__init__()\n",
    "        self.val_ds = val_ds        \n",
    "        self.compute_fn = compute_fn\n",
    "        self.steps = steps\n",
    "        self.margin = margin\n",
    "        self.loss_tracker = K.metrics.Mean(name='loss')\n",
    "        self.auroc_tracker = K.metrics.Mean(name='auroc')\n",
    "        self.aupr_tracker = K.metrics.Mean(name='aupr')\n",
    "        self.threshold_tracker = K.metrics.Mean(name='threshold')\n",
    "\n",
    "    def compute_loss(self, p, n, q):\n",
    "        \"soft margin semi-hard negatives\"\n",
    "\n",
    "        p_dist = tf.reduce_sum(tf.square(p - q), axis=1) # (batch, dim) -> (batch,)\n",
    "        n_dist = tf.reduce_sum(tf.square(n - q), axis=1)\n",
    "\n",
    "        # dp < dn < dp + margin\n",
    "        # mask = tf.logical_and(p_dist < n_dist, n_dist < (p_dist + self.margin)) # (batch, 1) bool\n",
    "\n",
    "        diff = p_dist - n_dist # (batch,)\n",
    "        soft_loss = tf.math.log1p(tf.exp(diff)) # (batch,)\n",
    "        loss = soft_loss\n",
    "\n",
    "        # manter apenas as distâncias moderadas\n",
    "        # loss = tf.boolean_mask(soft_loss, mask) # (batch,)\n",
    "        return tf.reduce_mean(loss) # em caso de mask ser all False TODO: VERIFICAR MÉDIA COM MASK\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        counter = 0\n",
    "        for p_episodes, n_episodes, q_episodes in self.val_ds:\n",
    "            num_episodes = p_episodes.shape[0]\n",
    "            p_batch_pred = tf.TensorArray(tf.float32, size=num_episodes)\n",
    "            n_batch_pred = tf.TensorArray(tf.float32, size=num_episodes)\n",
    "            q_batch_pred = tf.TensorArray(tf.float32, size=num_episodes)\n",
    "            for episode in range(num_episodes): # (# batch iterações)\n",
    "                p_inputs, n_inputs, q_inputs = p_episodes[episode], n_episodes[episode], q_episodes[episode]\n",
    "\n",
    "                # transforma todas as entradas em um único batch de (3*kshots, H, W, 3)\n",
    "                inputs = tf.concat([p_inputs, n_inputs, q_inputs], axis=0) # (P + N + Q)\n",
    "                kshots = inputs.shape[0] // 3\n",
    "\n",
    "                # extração de todos os vetores\n",
    "                embeddings = self.model.feature_extractor(inputs)\n",
    "                \n",
    "                # split de cada classe\n",
    "                p_embeddings = embeddings[0:kshots]\n",
    "                n_embeddings = embeddings[kshots:2*kshots]\n",
    "                q_embeddings = embeddings[-kshots:]\n",
    "\n",
    "                # médias do K-shot\n",
    "                p_vector = tf.reduce_mean(p_embeddings, axis=0)\n",
    "                n_vector = tf.reduce_mean(n_embeddings, axis=0)\n",
    "                q_vector = tf.reduce_mean(q_embeddings, axis=0)\n",
    "\n",
    "                # preencher os tensores dinâmicos\n",
    "                p_batch_pred = p_batch_pred.write(episode, p_vector)\n",
    "                n_batch_pred = n_batch_pred.write(episode, n_vector)\n",
    "                q_batch_pred = q_batch_pred.write(episode, q_vector)\n",
    "                \n",
    "            # após todas as inferências, recuperar o valor final (Batch, dim)\n",
    "            p_batch_pred = p_batch_pred.stack()\n",
    "            n_batch_pred = n_batch_pred.stack()\n",
    "            q_batch_pred = q_batch_pred.stack()\n",
    "            \n",
    "            # soft margin semi-hard triplet loss\n",
    "            loss = self.compute_loss(p_batch_pred, n_batch_pred, q_batch_pred)\n",
    "\n",
    "            auroc, aupr, fpr, tpr, J_threshold = self.compute_fn(p_batch_pred, n_batch_pred, q_batch_pred)\n",
    "\n",
    "            self.loss_tracker.update_state(loss)\n",
    "            self.auroc_tracker.update_state(auroc)\n",
    "            self.aupr_tracker.update_state(aupr)\n",
    "            self.threshold_tracker.update_state(J_threshold)\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "            if counter == self.steps:\n",
    "                break\n",
    "\n",
    "        loss = self.loss_tracker.result()\n",
    "        auroc = self.auroc_tracker.result()\n",
    "        aupr = self.aupr_tracker.result()\n",
    "        J_threshold = self.threshold_tracker.result()\n",
    "\n",
    "        # print(f\" | Epoch {epoch+1} | AUROC: {auroc:.4f} | AUPR: {aupr:.4f} | J_th: {J_threshold:.4f}\")\n",
    "        logs = logs or {}\n",
    "        logs['val_loss'] = loss.numpy()\n",
    "        logs['val_auroc'] = auroc.numpy()\n",
    "        logs['val_aupr'] = aupr.numpy()\n",
    "        logs['val_J_threshold'] = J_threshold.numpy()\n",
    "\n",
    "callbacks = [\n",
    "    VerificationMetrics(test_ds, compute_metrics, steps=2, margin=0.1)\n",
    "]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8540dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/model_v1.keras')\n",
    "model = K.models.load_model('models/model_v1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6990d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,    \n",
    "    epochs=3,\n",
    "    steps_per_epoch=100,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "history = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.TensorArray(size=0, dtype=tf.float32, dynamic_size=True)\n",
    "\n",
    "a.write(0, tf.zeros((4)))\n",
    "a.write(1, tf.ones((4)))\n",
    "\n",
    "a.stack()\n",
    "\n",
    "a = a.read()\n",
    "a - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c522d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for P, N, Q in train_ds:\n",
    "    P, N, Q = P[0], N[0], Q[0]\n",
    "\n",
    "    p_vector = model.feature_extractor.predict(P)\n",
    "    n_vector = model.feature_extractor.predict(N)\n",
    "    q_vector = model.feature_extractor.predict(Q)\n",
    "\n",
    "    p_vector = tf.reduce_mean(p_vector, axis=0)\n",
    "    n_vector = tf.reduce_mean(n_vector, axis=0)\n",
    "\n",
    "    p_dist = tf.reduce_sum(tf.square(p_vector - q_vector), axis=1) # (batch, 512) -> (batch, 1)\n",
    "    n_dist = tf.reduce_sum(tf.square(n_vector - q_vector), axis=1)\n",
    "\n",
    "    print(\"-\"*20)\n",
    "    print(f\"P dist: {p_dist} | N dist: {n_dist}\")\n",
    "    imtools.plot_images(P.numpy().astype('uint8'), scale=3)\n",
    "    imtools.plot_images(N.numpy().astype('uint8'), scale=3)\n",
    "    imtools.plot_images(Q.numpy().astype('uint8'), scale=3)\n",
    "    print(\"-\"*20)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30318d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n",
    "\n",
    "def make_scores_and_labels(p_dists, n_dists, use_exp=True):\n",
    "    \"\"\"\n",
    "    p_dists: array-like of positive distances (Q vs same-ID P)\n",
    "    n_dists: array-like of negative distances (Q vs different-ID N)\n",
    "    use_exp: if True use exp(-dist) as score, else use -dist\n",
    "    Returns: scores (1D), labels (1D)\n",
    "    \"\"\"\n",
    "    p_dists = np.asarray(p_dists).ravel()\n",
    "    n_dists = np.asarray(n_dists).ravel()\n",
    "    dists = np.concatenate([p_dists, n_dists])\n",
    "    if use_exp:\n",
    "        scores = np.exp(-dists)\n",
    "    else:\n",
    "        scores = -dists\n",
    "    labels = np.concatenate([np.ones_like(p_dists), np.zeros_like(n_dists)])\n",
    "    return scores, labels\n",
    "\n",
    "def compute_roc_pr_auc(p_dists, n_dists, use_exp=True):\n",
    "    scores, labels = make_scores_and_labels(p_dists, n_dists, use_exp)\n",
    "    roc_auc = roc_auc_score(labels, scores)\n",
    "    pr_auc  = average_precision_score(labels, scores)  # PR AUC (average precision)\n",
    "    return {'roc_auc': roc_auc, 'pr_auc': pr_auc}\n",
    "\n",
    "def compute_eer_and_threshold(p_dists, n_dists, use_exp=True):\n",
    "    scores, labels = make_scores_and_labels(p_dists, n_dists, use_exp)\n",
    "    fpr, tpr, thresh = roc_curve(labels, scores)\n",
    "    fnr = 1 - tpr\n",
    "    # EER: point where FPR ~= FNR (pick the threshold minimizing absolute difference)\n",
    "    idx = np.nanargmin(np.abs(fpr - fnr))\n",
    "    eer = (fpr[idx] + fnr[idx]) / 2.0\n",
    "    eer_threshold = thresh[idx]\n",
    "    return {'eer': eer, 'eer_threshold': eer_threshold, 'fpr': fpr, 'tpr': tpr, 'thresholds': thresh}\n",
    "\n",
    "def tpr_at_target_fpr(p_dists, n_dists, target_fpr=1e-3, use_exp=True):\n",
    "    scores, labels = make_scores_and_labels(p_dists, n_dists, use_exp)\n",
    "    fpr, tpr, thresh = roc_curve(labels, scores)\n",
    "    valid = np.where(fpr <= target_fpr)[0]\n",
    "    if valid.size == 0:\n",
    "        return {'tpr': 0.0, 'threshold': None}\n",
    "    idx = valid[-1]  # max TPR with FPR <= target\n",
    "    return {'tpr': tpr[idx], 'threshold': thresh[idx], 'fpr': fpr[idx]}\n",
    "\n",
    "###############################################\n",
    "def compute_metrics(p_dists, n_dists):\n",
    "    # distâncias negativas para melhor interpretabilidade das métricas\n",
    "    # \"quanto maior -d, mais parecido com o positivo\"\n",
    "    scores = -np.concatenate([p_dists, n_dists])\n",
    "    labels = np.concatenate([np.ones_like(p_dists), np.zeros_like(n_dists)])\n",
    "    \n",
    "    auroc = roc_auc_score(labels, scores)           # ROC-AUC\n",
    "    aupr  = average_precision_score(labels, scores) # PR-AUC\n",
    "\n",
    "    # Youlden's J threshold\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "    J = tpr - fpr\n",
    "    idx = np.argmax(J)\n",
    "    J_threshold = thresholds[idx]\n",
    "\n",
    "    return auroc, aupr, fpr, tpr, J_threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9332ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated dists (positives generally smaller than negatives)\n",
    "p_dists = np.random.normal(0.6, 0.12, size=2000)\n",
    "n_dists = np.random.normal(1.2, 0.25, size=2000)\n",
    "\n",
    "print(compute_roc_pr_auc(p_dists, n_dists, use_exp=False))\n",
    "print(compute_eer_and_threshold(p_dists, n_dists, use_exp=False)['eer'])\n",
    "print(tpr_at_target_fpr(p_dists, n_dists, target_fpr=1e-3, use_exp=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
